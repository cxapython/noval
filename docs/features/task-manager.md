# 📡 任务管理系统

任务管理系统提供实时的爬虫任务执行、监控和管理功能。

## 🌟 功能特性

- ✅ 实时任务进度追踪
- ✅ WebSocket实时日志推送
- ✅ 多任务并发执行
- ✅ 任务暂停和取消
- ✅ 历史任务查询
- ✅ 错误日志记录
- ✅ 性能统计分析

---

## 🚀 快速开始

### 访问任务管理器

访问 http://localhost:3000/tasks

### 创建新任务

#### 步骤1：选择配置

从下拉菜单中选择要使用的爬虫配置。

#### 步骤2：输入参数

根据内容类型输入对应的ID：
- 小说：小说ID
- 新闻：新闻ID
- 文章：文章ID
- 博客：博客ID

#### 步骤3：配置选项

**基础选项**：
- 并发数（Workers）：1-20，默认5
- 使用代理：开启/关闭

**高级选项**：
- 超时时间：请求超时设置
- 重试次数：失败后重试次数
- 延迟时间：请求间隔延迟

#### 步骤4：开始爬取

点击"开始爬取"按钮，任务开始执行。

---

## 📊 任务监控

### 实时进度

任务运行时显示：

1. **进度条**
   - 当前进度百分比
   - 已完成/总数量
   - 预计剩余时间

2. **状态信息**
   - 任务状态（运行中/暂停/完成/失败）
   - 开始时间
   - 运行时长

3. **性能指标**
   - 爬取速度（章节/分钟）
   - 成功率
   - 错误数量

### 实时日志

WebSocket实时推送日志：

```
[2025-10-15 10:30:00] 开始爬取: 小说ID 12345
[2025-10-15 10:30:01] 获取小说信息...
[2025-10-15 10:30:02] ✅ 小说标题: "我的小说"
[2025-10-15 10:30:02] ✅ 作者: "作者名"
[2025-10-15 10:30:03] 获取章节列表...
[2025-10-15 10:30:05] ✅ 发现 100 个章节
[2025-10-15 10:30:06] 开始爬取章节内容 (并发数: 5)
[2025-10-15 10:30:10] ✅ [1/100] 第一章
[2025-10-15 10:30:12] ✅ [2/100] 第二章
...
```

**日志级别**：
- ✅ **INFO** - 正常信息（绿色）
- ⚠️ **WARNING** - 警告信息（黄色）
- ❌ **ERROR** - 错误信息（红色）
- 📊 **PROGRESS** - 进度更新（蓝色）

### 日志过滤

可以按日志级别过滤：
- 全部日志
- 仅错误
- 仅警告
- 仅信息

---

## 🎮 任务控制

### 暂停任务

点击"暂停"按钮：
- 当前正在执行的章节会完成
- 后续章节暂停爬取
- 可以随时恢复

### 恢复任务

点击"继续"按钮：
- 从暂停的位置继续
- 保持之前的配置
- 进度不会丢失

### 取消任务

点击"取消"按钮：
- 立即停止任务
- 已爬取的数据保留
- 任务标记为已取消

### 重试失败项

如果任务中有失败的章节：
1. 点击"重试失败项"按钮
2. 系统只重新爬取失败的章节
3. 成功的章节不会重复爬取

---

## 📝 任务列表

### 任务状态

| 状态 | 说明 | 图标 |
|-----|------|------|
| **运行中** | 正在执行 | 🔄 |
| **暂停** | 已暂停 | ⏸️ |
| **完成** | 成功完成 | ✅ |
| **失败** | 执行失败 | ❌ |
| **已取消** | 用户取消 | 🚫 |

### 任务信息

每个任务显示：
- 配置名称
- 目标ID
- 创建时间
- 完成进度
- 运行时长
- 成功/失败数量

### 任务操作

- **查看详情** - 查看完整日志
- **重新运行** - 使用相同参数重新运行
- **删除任务** - 删除任务记录

---

## 📈 性能统计

### 实时统计

**爬取速度**：
- 当前速度：X 章节/分钟
- 平均速度：Y 章节/分钟
- 峰值速度：Z 章节/分钟

**成功率**：
- 成功数量 / 总数量
- 失败率百分比
- 重试次数

**时间统计**：
- 已运行时间
- 预计剩余时间
- 完成时间（预估）

### 历史统计

查看所有历史任务的统计：
- 总任务数
- 成功任务数
- 失败任务数
- 总爬取章节数
- 平均成功率

---

## 🔧 高级功能

### 并发控制

**并发数设置**：
- 1-5：保守模式，适合限制较严的网站
- 5-10：标准模式，适合大多数网站
- 10-20：激进模式，适合限制较松的网站

**注意事项**：
- 并发数过高可能被封IP
- 建议先从低并发测试
- 配合代理使用可提高并发

### 代理配置

**使用代理**：
1. 启用"使用代理"选项
2. 系统会自动使用配置的代理池
3. 自动轮换代理IP

**代理配置**：
编辑 `shared/utils/proxy_utils.py`：

```python
PROXY_POOL = [
    "http://proxy1:port",
    "http://proxy2:port",
    "http://proxy3:port"
]
```

### 错误处理

**自动重试**：
- 网络错误自动重试
- 可配置重试次数
- 指数退避策略

**错误分类**：
- 网络错误（可重试）
- 解析错误（配置问题）
- 403/404错误（资源问题）

### 任务持久化

**自动保存**：
- 任务状态实时保存到数据库
- 进度自动记录
- 服务重启后可恢复

**数据保存**：
- 小说信息保存到 `novels` 表
- 章节内容保存到 `chapters` 表
- 可在阅读器中查看

---

## 📊 WebSocket 通信

### 连接建立

前端自动连接WebSocket服务：

```javascript
const socket = io('http://localhost:5001');

socket.on('connect', () => {
  console.log('WebSocket连接成功');
});
```

### 事件监听

**进度更新**：
```javascript
socket.on('progress', (data) => {
  // data: { current: 10, total: 100, percent: 10 }
});
```

**日志推送**：
```javascript
socket.on('log', (data) => {
  // data: { level: 'info', message: '...' }
});
```

**任务完成**：
```javascript
socket.on('task_complete', (data) => {
  // data: { success: true, stats: {...} }
});
```

---

## 💡 使用技巧

### 1. 选择合适的并发数

**测试方法**：
1. 从并发数1开始
2. 观察是否有错误
3. 逐步提高并发数
4. 找到最佳平衡点

### 2. 监控错误日志

**关注**：
- 403错误 → 可能被限制，降低并发或使用代理
- 404错误 → URL模板可能有问题
- 超时错误 → 增加超时时间或减少并发
- 解析错误 → 检查XPath配置

### 3. 优化爬取速度

**策略**：
1. 使用合适的并发数
2. 配置代理池
3. 减少不必要的字段提取
4. 优化XPath表达式

### 4. 处理大型任务

**建议**：
- 分批爬取（按章节范围）
- 使用断点续传
- 定期检查进度
- 保存中间结果

---

## 🐛 常见问题

### Q1: WebSocket连接失败？

**检查**：
- [ ] 后端服务是否运行
- [ ] 端口5001是否开放
- [ ] 防火墙设置
- [ ] 浏览器控制台错误

**解决**：
```bash
# 检查后端服务
ps aux | grep api.py

# 重启后端
./stop.sh && ./start.sh
```

### Q2: 任务一直卡在某个章节？

**原因**：
- 目标章节不存在
- 网络问题
- 网站反爬

**解决**：
1. 点击"取消"停止任务
2. 查看错误日志
3. 检查配置是否正确
4. 手动访问问题章节URL

### Q3: 爬取速度很慢？

**优化**：
1. 提高并发数
2. 使用代理
3. 检查网络连接
4. 减少后处理规则

### Q4: 任务完成但数据不全？

**检查**：
1. 查看失败数量
2. 使用"重试失败项"
3. 检查错误日志
4. 验证配置正确性

### Q5: 内存占用过高？

**原因**：
- 并发数过高
- 章节内容过大
- 日志积累过多

**解决**：
1. 降低并发数
2. 清理历史日志
3. 分批爬取
4. 增加服务器内存

---

## 📊 性能基准

### 典型场景

| 场景 | 并发数 | 速度 | 成功率 |
|-----|-------|------|-------|
| 小说网站 | 5 | 30章节/分钟 | 95%+ |
| 新闻网站 | 10 | 50文章/分钟 | 98%+ |
| 使用代理 | 15 | 60章节/分钟 | 90%+ |

### 资源占用

| 并发数 | CPU | 内存 | 网络 |
|-------|-----|------|------|
| 1-5 | 10-20% | 200MB | 1-5 Mbps |
| 5-10 | 20-40% | 400MB | 5-10 Mbps |
| 10-20 | 40-60% | 800MB | 10-20 Mbps |

---

## 📚 相关文档

- [爬虫配置管理](crawler-manager.md) - 创建和管理配置
- [使用示例](../user-guides/usage-examples.md) - 完整使用流程
- [常见问题](../faq/faq.md) - 疑难问题解答

---

**返回**: [文档中心](../README.md) | **上一篇**: [爬虫配置管理](crawler-manager.md) | **下一篇**: [小说阅读器](novel-reader.md)

