# ç”Ÿæˆä»£ç åŠŸèƒ½åˆ†ææŠ¥å‘Š

## ğŸ“‹ åˆ†ææ—¥æœŸ
2025-10-07

## ğŸ¯ åˆ†æç›®æ ‡
æ£€æŸ¥ç”Ÿæˆä»£ç åŠŸèƒ½å’Œ `generic_crawler.py` æ–‡ä»¶æ˜¯å¦å­˜åœ¨é—®é¢˜ï¼Œç”Ÿæˆçš„çˆ¬è™«ä»£ç æ˜¯å¦å¯ä»¥ç›´æ¥è¿è¡Œã€‚

---

## âœ… generic_crawler.py æ–‡ä»¶åˆ†æ

### æ•´ä½“è¯„ä»·ï¼š**ä¼˜ç§€**

### ä¼˜ç‚¹
1. âœ… **æ¨¡å—åŒ–è®¾è®¡å®Œå–„**
   - ConfigManagerï¼šé…ç½®ç®¡ç†
   - HtmlParserï¼šHTMLè§£æ
   - ContentFetcherï¼šHTTPè¯·æ±‚
   - GenericNovelCrawlerï¼šæ ¸å¿ƒçˆ¬è™«é€»è¾‘

2. âœ… **åŠŸèƒ½å®Œæ•´**
   - å¤šçº¿ç¨‹å¹¶å‘ä¸‹è½½
   - å®Œæ•´çš„é”™è¯¯å¤„ç†å’Œé‡è¯•æœºåˆ¶
   - Redisç¼“å­˜æ”¯æŒï¼ˆè®°å½•æˆåŠŸ/å¤±è´¥ç« èŠ‚ï¼‰
   - æ”¯æŒç« èŠ‚åˆ—è¡¨å’Œå†…å®¹åˆ†é¡µ
   - å›è°ƒå‡½æ•°æ”¯æŒï¼ˆè¿›åº¦ã€æ—¥å¿—ã€åœæ­¢æ ‡å¿—ï¼‰

3. âœ… **ä»£ç è´¨é‡é«˜**
   - å®Œæ•´çš„æ—¥å¿—è®°å½•
   - è¯¦ç»†çš„æ³¨é‡Šæ–‡æ¡£
   - ç±»å‹æç¤º
   - å¼‚å¸¸å¤„ç†å®Œå–„

### ç»“è®º
**generic_crawler.py æ–‡ä»¶æ— é—®é¢˜ï¼Œå¯ä»¥æ­£å¸¸ä½¿ç”¨ã€‚**

---

## âš ï¸ ç”Ÿæˆä»£ç åŠŸèƒ½é—®é¢˜åˆ†æ

### ä¿®å¤å‰çš„é—®é¢˜

#### é—®é¢˜1ï¼šä¿å­˜è·¯å¾„è®¾è®¡ä¸åˆç† ğŸ”´
**ç°è±¡ï¼š**
- åŸè®¾è®¡ä¿å­˜åˆ°ï¼š`crawler-manager/backend/crawlers/`
- è¯¥ç›®å½•ä¸å­˜åœ¨äºé¡¹ç›®ç»“æ„ä¸­
- è¿è¡Œè·¯å¾„è¿‡æ·±ï¼Œä¸ä¾¿äºä½¿ç”¨

**å½±å“ï¼š**
- ç”Ÿæˆçš„çˆ¬è™«æ–‡ä»¶æ— æ³•ä¿å­˜
- å³ä½¿ä¿å­˜æˆåŠŸï¼Œè·¯å¾„è®¡ç®—å¤æ‚

#### é—®é¢˜2ï¼šconfigs/ikbook8_crawler.py æ–‡ä»¶é”™è¯¯ ğŸ”´
**ç°è±¡ï¼š**
- æ–‡ä»¶ä½ç½®é”™è¯¯ï¼ˆåœ¨ configs/ è€Œéæ­£ç¡®çš„çˆ¬è™«ç›®å½•ï¼‰
- å¯¼å…¥è¯­å¥é”™è¯¯ï¼š`from generic_crawler import GenericNovelCrawler`
- é…ç½®æ–‡ä»¶è·¯å¾„é”™è¯¯

**åŸå› ï¼š**
è¿™æ˜¯ä¸€ä¸ªæ—§ç‰ˆæœ¬çš„æ‰‹åŠ¨åˆ›å»ºæ–‡ä»¶ï¼Œä¸æ˜¯é€šè¿‡ç”ŸæˆåŠŸèƒ½åˆ›å»ºçš„ã€‚

---

## ğŸ› ï¸ ä¿®å¤æ–¹æ¡ˆ

### ä¿®å¤1ï¼šç®€åŒ–ä¿å­˜è·¯å¾„
```python
# ä¿®æ”¹å‰
CRAWLER_DIR = Path(__file__).parent.parent.parent / 'crawler-manager' / 'backend' / 'crawlers'

# ä¿®æ”¹å
CRAWLER_DIR = Path(__file__).parent.parent.parent  # é¡¹ç›®æ ¹ç›®å½•
```

**ä¼˜ç‚¹ï¼š**
- çˆ¬è™«æ–‡ä»¶ç›´æ¥ä¿å­˜åœ¨é¡¹ç›®æ ¹ç›®å½•
- è¿è¡Œç®€å•ï¼š`python xxx_crawler.py book_id`
- é…ç½®æ–‡ä»¶åœ¨ `./configs/` ç›®å½•ï¼Œè·¯å¾„æ¸…æ™°

### ä¿®å¤2ï¼šæ›´æ–°ä»£ç æ¨¡æ¿

**è·¯å¾„è®¡ç®—ï¼š**
```python
# ä¿®æ”¹å‰
sys.path.insert(0, str(Path(__file__).parent.parent.parent.parent))
config_path = Path(__file__).parent.parent.parent.parent / "configs" / "{config_file}"

# ä¿®æ”¹å
sys.path.insert(0, str(Path(__file__).parent))
config_path = Path(__file__).parent / "configs" / "{config_file}"
```

**ä½¿ç”¨ç¤ºä¾‹æ›´æ–°ï¼š**
```python
# ä¿®æ”¹å‰
python crawler-manager/backend/crawlers/ikbook8_crawler.py 12345

# ä¿®æ”¹å
python ikbook8_crawler.py 12345
```

### ä¿®å¤3ï¼šåˆ é™¤é”™è¯¯æ–‡ä»¶
```bash
rm configs/ikbook8_crawler.py
```

---

## âœ… ä¿®å¤åæµ‹è¯•ç»“æœ

### æµ‹è¯•1ï¼šä»£ç ç”Ÿæˆ
```bash
âœ… æµ‹è¯•æ–‡ä»¶å·²ç”Ÿæˆ: ikbook8_crawler.py
âœ… æ–‡ä»¶å¤§å°: 3353 bytes
```

### æµ‹è¯•2ï¼šå¯¼å…¥æµ‹è¯•
```bash
âœ… å¯¼å…¥ GenericNovelCrawler æˆåŠŸ
âœ… é…ç½®æ–‡ä»¶å­˜åœ¨: configs/config_ikbook8.json
âœ… GenericNovelCrawler åˆå§‹åŒ–æˆåŠŸ
   ç½‘ç«™: ikbook8
   åŸºç¡€URL: https://m.ikbook8.com
```

### æµ‹è¯•3ï¼šå‘½ä»¤è¡Œå‚æ•°
```bash
$ python ikbook8_crawler.py --help

usage: ikbook8_crawler.py [-h] [-w WORKERS] [-p] book_id

ikbook8 å°è¯´çˆ¬è™«

positional arguments:
  book_id               ä¹¦ç±IDï¼ˆä»ç½‘ç«™URLä¸­è·å–ï¼‰

optional arguments:
  -h, --help            show this help message and exit
  -w WORKERS, --workers WORKERS
                        å¹¶å‘çº¿ç¨‹æ•°ï¼ˆé»˜è®¤: 5ï¼‰
  -p, --proxy           ä½¿ç”¨ä»£ç†
```

---

## ğŸ“ ç”Ÿæˆçš„çˆ¬è™«ä»£ç ç»“æ„

```python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
{site_name} å°è¯´çˆ¬è™« - åŸºäºé€šç”¨çˆ¬è™«æ¡†æ¶
"""
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

from loguru import logger
from backend.generic_crawler import GenericNovelCrawler


class {SiteName}Crawler:
    """ç½‘ç«™çˆ¬è™«ç±»"""
    
    def __init__(self, book_id: str, max_workers: int = 5, use_proxy: bool = False):
        """åˆå§‹åŒ–çˆ¬è™«"""
        config_path = Path(__file__).parent / "configs" / "{config_file}"
        self.crawler = GenericNovelCrawler(
            config_file=str(config_path),
            book_id=book_id,
            max_workers=max_workers,
            use_proxy=use_proxy
        )
    
    def run(self):
        """è¿è¡Œçˆ¬è™«"""
        self.crawler.run()


def main():
    """å‘½ä»¤è¡Œå…¥å£"""
    # argparse å‚æ•°è§£æ
    # æ”¯æŒï¼šbook_id, --workers, --proxy
    pass


if __name__ == '__main__':
    main()
```

---

## ğŸ¯ ä½¿ç”¨æ–¹å¼

### ä»é¡¹ç›®æ ¹ç›®å½•è¿è¡Œ

```bash
# åŸºæœ¬ç”¨æ³•
python ikbook8_crawler.py 12345

# ä½¿ç”¨ä»£ç†
python ikbook8_crawler.py 12345 --proxy

# æŒ‡å®šå¹¶å‘æ•°
python ikbook8_crawler.py 12345 --workers 10

# ç»„åˆä½¿ç”¨
python ikbook8_crawler.py 12345 --proxy --workers 10
```

### é¡¹ç›®ç»“æ„
```
noval/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ generic_crawler.py      # é€šç”¨çˆ¬è™«å¼•æ“
â”‚   â”œâ”€â”€ config_manager.py        # é…ç½®ç®¡ç†
â”‚   â”œâ”€â”€ parser.py                # è§£æå™¨
â”‚   â””â”€â”€ content_fetcher.py       # å†…å®¹è·å–
â”œâ”€â”€ configs/
â”‚   â”œâ”€â”€ config_ikbook8.json      # ikbook8é…ç½®
â”‚   â””â”€â”€ config_template.json     # é…ç½®æ¨¡æ¿
â”œâ”€â”€ ikbook8_crawler.py           # ç”Ÿæˆçš„çˆ¬è™« âœ…
â””â”€â”€ djks5_crawler.py             # ç”Ÿæˆçš„çˆ¬è™« âœ…
```

---

## âœ… ç»“è®º

### é—®é¢˜ä¿®å¤çŠ¶æ€
1. âœ… **ä¿å­˜è·¯å¾„é—®é¢˜** - å·²ä¿®å¤ï¼Œç®€åŒ–ä¸ºé¡¹ç›®æ ¹ç›®å½•
2. âœ… **ä»£ç æ¨¡æ¿é—®é¢˜** - å·²ä¿®å¤ï¼Œè·¯å¾„è®¡ç®—æ­£ç¡®
3. âœ… **é”™è¯¯æ–‡ä»¶æ¸…ç†** - å·²åˆ é™¤æ—§æ–‡ä»¶

### åŠŸèƒ½éªŒè¯
1. âœ… **ä»£ç ç”Ÿæˆ** - æ­£å¸¸å·¥ä½œ
2. âœ… **æ–‡ä»¶ä¿å­˜** - æ­£å¸¸å·¥ä½œ
3. âœ… **å¯¼å…¥æµ‹è¯•** - æˆåŠŸ
4. âœ… **åˆå§‹åŒ–æµ‹è¯•** - æˆåŠŸ
5. âœ… **å‘½ä»¤è¡Œå‚æ•°** - æ­£å¸¸å·¥ä½œ

### æœ€ç»ˆè¯„ä»·
**ç”Ÿæˆçš„çˆ¬è™«ä»£ç ç°åœ¨å¯ä»¥ç›´æ¥è¿è¡Œï¼** âœ…

---

## ğŸ“š ç›¸å…³æ–‡æ¡£
- [é€šç”¨çˆ¬è™«ä½¿ç”¨æŒ‡å—](../README.md)
- [é…ç½®æ–‡ä»¶è¯´æ˜](./URLæ¨¡æ¿é…ç½®è¯´æ˜.md)
- [æµç¨‹é…ç½®è§†å›¾ä½¿ç”¨æŒ‡å—](./æµç¨‹é…ç½®è§†å›¾ä½¿ç”¨æŒ‡å—.md)

---

**æŠ¥å‘Šå®Œæˆæ—¥æœŸï¼š** 2025-10-07  
**ä¿®å¤çŠ¶æ€ï¼š** âœ… å®Œæˆ  
**æµ‹è¯•çŠ¶æ€ï¼š** âœ… é€šè¿‡
