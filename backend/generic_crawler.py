#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é€šç”¨å°è¯´çˆ¬è™«æ¡†æ¶ - æ¨¡å—åŒ–ç‰ˆæœ¬
èŒè´£æ‹†åˆ†ï¼š
- ConfigManager: é…ç½®ç®¡ç†
- HtmlParser: HTMLè§£æ
- ContentFetcher: HTTPè¯·æ±‚
- GenericNovelCrawler: æ ¸å¿ƒçˆ¬è™«é€»è¾‘å’Œä»»åŠ¡åè°ƒ
"""
import re
import time
from concurrent.futures import ThreadPoolExecutor, as_completed
from threading import Lock
from urllib.parse import urljoin
from typing import Dict, List, Optional

from loguru import logger
from scrapy import Selector
from redis import Redis

import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from shared.utils.config import DB_CONFIG
from backend.models.database import NovelDatabase
from shared.utils.proxy_utils import ProxyUtils
from backend.config_manager import ConfigManager
from backend.parser import HtmlParser
from backend.content_fetcher import ContentFetcher

REDIS_URL = "redis://@localhost:6379"
redis_cli = Redis.from_url(REDIS_URL)


class GenericNovelCrawler:
    """é€šç”¨å°è¯´çˆ¬è™« - æ¨¡å—åŒ–ç‰ˆæœ¬"""
    
    def __init__(self, config_file: str, book_id: str, max_workers: int = 5, use_proxy: bool = False, 
                 progress_callback=None, log_callback=None, stop_flag=None):
        """
        åˆå§‹åŒ–çˆ¬è™«
        :param config_file: é…ç½®æ–‡ä»¶è·¯å¾„
        :param book_id: ä¹¦ç±ID
        :param max_workers: å¹¶å‘çº¿ç¨‹æ•°
        :param use_proxy: æ˜¯å¦ä½¿ç”¨ä»£ç†
        :param progress_callback: è¿›åº¦å›è°ƒå‡½æ•° (total, completed, failed, current_chapter)
        :param log_callback: æ—¥å¿—å›è°ƒå‡½æ•° (level, message)
        :param stop_flag: åœæ­¢æ ‡å¿— (threading.Event)
        """
        self.book_id = book_id
        self.max_workers = max_workers
        self.use_proxy = use_proxy
        
        # å›è°ƒå‡½æ•°
        self.progress_callback = progress_callback
        self.log_callback = log_callback
        self.stop_flag = stop_flag
        
        # åˆå§‹åŒ–é…ç½®ç®¡ç†å™¨
        self.config_manager = ConfigManager(config_file)
        site_info = self.config_manager.get_site_info()
        
        self.site_name = site_info.get('name')
        self.base_url = site_info.get('base_url')
        self.start_url = self.config_manager.build_url('book_detail', book_id)
        
        # åˆå§‹åŒ–HTMLè§£æå™¨
        self.parser = HtmlParser(self.base_url)
        
        # åˆå§‹åŒ–ä»£ç†å·¥å…·
        proxy_utils = None
        if use_proxy:
            proxy_utils = ProxyUtils()
            self._log('INFO', "âœ… å·²å¯ç”¨ä»£ç†")
        
        # åˆå§‹åŒ–å†…å®¹è·å–å™¨
        self.fetcher = ContentFetcher(
            headers=self.config_manager.get_headers(),
            timeout=self.config_manager.get_timeout(),
            encoding=self.config_manager.get_encoding(),
            proxy_utils=proxy_utils
        )
        
        # æ•°æ®å­˜å‚¨
        self.chapters = []
        self.novel_info = {}
        self.novel_id = None
        self.db = NovelDatabase(**DB_CONFIG)
        
        # å¹¶å‘é…ç½®
        self.progress_lock = Lock()
        self.completed_count = 0
        self.skipped_count = 0
        
        # Redisé…ç½®
        self.redis_cli = redis_cli
        self.redis_success_key = f"novel:success:{self.site_name}:{book_id}"
        self.redis_failed_key = f"novel:failed:{self.site_name}:{book_id}"
        
        self._log('INFO', f"ğŸŒ ç½‘ç«™: {self.site_name}")
        self._log('INFO', f"ğŸ“– ä¹¦ç±ID: {book_id}")
    
    def _log(self, level: str, message: str):
        """ç»Ÿä¸€æ—¥å¿—è¾“å‡º"""
        logger_func = {
            'INFO': logger.info,
            'WARNING': logger.warning,
            'ERROR': logger.error,
            'SUCCESS': logger.success
        }.get(level, logger.info)
        
        logger_func(message)
        
        # è°ƒç”¨æ—¥å¿—å›è°ƒ
        if self.log_callback:
            try:
                self.log_callback(level, message)
            except Exception as e:
                logger.error(f"æ—¥å¿—å›è°ƒå¤±è´¥: {e}")
    
    def _update_progress(self, **kwargs):
        """æ›´æ–°è¿›åº¦"""
        if self.progress_callback:
            try:
                self.progress_callback(**kwargs)
            except Exception as e:
                logger.error(f"è¿›åº¦å›è°ƒå¤±è´¥: {e}")
    
    def _check_stop(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦åº”è¯¥åœæ­¢"""
        if self.stop_flag and self.stop_flag.is_set():
            return True
        return False
    
    def is_chapter_downloaded(self, chapter_url: str) -> bool:
        """æ£€æŸ¥ç« èŠ‚æ˜¯å¦å·²ä¸‹è½½"""
        try:
            return self.redis_cli.sismember(self.redis_success_key, chapter_url)
        except Exception as e:
            logger.warning(f"âš ï¸  Redisæ£€æŸ¥å¤±è´¥: {e}")
            return False
    
    def mark_chapter_success(self, chapter_url: str):
        """æ ‡è®°ç« èŠ‚ä¸‹è½½æˆåŠŸ"""
        try:
            self.redis_cli.sadd(self.redis_success_key, chapter_url)
            self.redis_cli.srem(self.redis_failed_key, chapter_url)
            self.redis_cli.expire(self.redis_success_key, 30 * 24 * 3600)
        except Exception as e:
            logger.warning(f"âš ï¸  Redisè®°å½•æˆåŠŸå¤±è´¥: {e}")
    
    def mark_chapter_failed(self, chapter_url: str):
        """æ ‡è®°ç« èŠ‚ä¸‹è½½å¤±è´¥"""
        try:
            self.redis_cli.sadd(self.redis_failed_key, chapter_url)
            self.redis_cli.expire(self.redis_failed_key, 7 * 24 * 3600)
        except Exception as e:
            logger.warning(f"âš ï¸  Redisè®°å½•å¤±è´¥å¤±è´¥: {e}")
    
    def get_download_stats(self):
        """è·å–ä¸‹è½½ç»Ÿè®¡"""
        try:
            success_count = self.redis_cli.scard(self.redis_success_key)
            failed_count = self.redis_cli.scard(self.redis_failed_key)
            return success_count, failed_count
        except Exception as e:
            logger.warning(f"âš ï¸  Redisè·å–ç»Ÿè®¡å¤±è´¥: {e}")
            return 0, 0
    
    def clear_failed_records(self):
        """æ¸…é™¤å¤±è´¥è®°å½•"""
        try:
            count = self.redis_cli.scard(self.redis_failed_key)
            if count > 0:
                self.redis_cli.delete(self.redis_failed_key)
                logger.info(f"ğŸ—‘ï¸  å·²æ¸…é™¤ {count} æ¡å¤±è´¥è®°å½•")
        except Exception as e:
            logger.warning(f"âš ï¸  æ¸…é™¤å¤±è´¥è®°å½•å¤±è´¥: {e}")
    
    def parse_novel_info(self, html: str) -> Dict:
        """è§£æå°è¯´ä¿¡æ¯"""
        novel_info = {}
        parsers = self.config_manager.get_parsers().get('novel_info', {})
        
        # éªŒè¯é…ç½®ç±»å‹
        if not isinstance(parsers, dict):
            logger.error(f"âŒ novel_info é…ç½®åº”ä¸ºå­—å…¸ç±»å‹ï¼Œå®é™…ä¸º {type(parsers).__name__}")
            return novel_info
        
        for field, parser_config in parsers.items():
            # è·³è¿‡æ³¨é‡Šå­—æ®µ
            if field.startswith('_'):
                continue
            
            try:
                value = self.parser.parse_with_config(html, parser_config)
                novel_info[field] = value
            except Exception as e:
                logger.warning(f"âš ï¸  è§£æå­—æ®µ {field} å¤±è´¥: {e}")
                novel_info[field] = None
        
        return novel_info
    
    def parse_chapter_list(self) -> bool:
        """è§£æç« èŠ‚åˆ—è¡¨"""
        self._log('INFO', f"ğŸ“– å¼€å§‹è·å–ç« èŠ‚åˆ—è¡¨...")
        self._log('INFO', f"ğŸ”— å°è¯´åœ°å€: {self.start_url}")
        
        # è·å–é¦–é¡µ
        html = self.fetcher.get_page(self.start_url, 
                                     max_retries=self.config_manager.get_max_retries())
        if not html:
            self._log('ERROR', "âŒ è·å–é¦–é¡µå¤±è´¥")
            return False
        
        # è§£æå°è¯´ä¿¡æ¯
        self.novel_info = self.parse_novel_info(html)
        
        if not self.novel_info.get('title'):
            self._log('ERROR', "âŒ è§£æå°è¯´ä¿¡æ¯å¤±è´¥")
            return False
        
        self._log('INFO', f"ğŸ“š å°è¯´åç§°: {self.novel_info.get('title')}")
        self._log('INFO', f"âœï¸  ä½œè€…: {self.novel_info.get('author', 'æœªçŸ¥')}")
        
        # è§£æç« èŠ‚åˆ—è¡¨é…ç½®
        parsers = self.config_manager.get_parsers()
        chapter_list_config = parsers.get('chapter_list', {})
        
        # æ£€æŸ¥æ˜¯å¦æœ‰åˆ†é¡µ
        pagination_config = chapter_list_config.get('pagination')
        if pagination_config and pagination_config.get('enabled', False):
            # æœ‰åˆ†é¡µ
            max_page = self._get_max_page(html, pagination_config)
            logger.info(f"ğŸ“„ å…± {max_page} é¡µç« èŠ‚åˆ—è¡¨")
            
            for page in range(1, max_page + 1):
                if page == 1:
                    page_html = html
                else:
                    page_url = self._build_pagination_url(page, pagination_config)
                    logger.info(f"ğŸ“„ è·å–ç¬¬ {page} é¡µ: {page_url}")
                    page_html = self.fetcher.get_page(page_url,
                                                      max_retries=self.config_manager.get_max_retries())
                    
                    if not page_html:
                        logger.warning(f"âš ï¸  ç¬¬ {page} é¡µè·å–å¤±è´¥")
                        break
                
                chapters = self._parse_chapters_from_page(page_html, chapter_list_config)
                self.chapters.extend(chapters)
                logger.info(f"   âœ“ æœ¬é¡µè·å– {len(chapters)} ç« ï¼Œç´¯è®¡ {len(self.chapters)} ç« ")
        else:
            # æ— åˆ†é¡µ
            chapters = self._parse_chapters_from_page(html, chapter_list_config)
            self.chapters.extend(chapters)
        
        logger.info(f"\nâœ… ç« èŠ‚åˆ—è¡¨è·å–å®Œæˆï¼Œå…± {len(self.chapters)} ç« \n")
        return True
    
    def _get_max_page(self, html: str, pagination_config: Dict) -> int:
        """è·å–æœ€å¤§é¡µæ•°"""
        max_page_config = pagination_config.get('max_page')
        if max_page_config:
            result = self.parser.parse_with_config(html, max_page_config)
            if result:
                # å¯èƒ½éœ€è¦ä»æ–‡æœ¬ä¸­æå–æ•°å­—
                if isinstance(result, str):
                    numbers = re.findall(r'\d+', result)
                    if numbers:
                        return int(numbers[0])
                elif isinstance(result, (int, float)):
                    return int(result)
        return 1
    
    def _build_pagination_url(self, page: int, pagination_config: Dict) -> str:
        """æ„å»ºåˆ†é¡µURL"""
        url_pattern = pagination_config.get('url_pattern', '')
        return url_pattern.format(base_url=self.base_url, book_id=self.book_id, page=page)
    
    def _build_content_next_page_url(self, chapter_url: str, page: int, next_page_config: Dict) -> str:
        """
        æ„å»ºç« èŠ‚å†…å®¹ç¿»é¡µURL
        :param chapter_url: ç« èŠ‚URLï¼Œç”¨äºæå–book_idå’Œchapter_id
        :param page: é¡µç 
        :param next_page_config: next_pageé…ç½®
        :return: ä¸‹ä¸€é¡µURLï¼Œå¦‚æœurl_patternä¸ºç©ºåˆ™è¿”å›None
        """
        url_pattern = next_page_config.get('url_pattern', '').strip()
        if not url_pattern:
            # url_patternä¸ºç©ºï¼Œä½¿ç”¨XPathæå–é“¾æ¥
            return None
        
        # ä»chapter_urlä¸­æå–book_idå’Œchapter_id
        # æŒ‰ç…§æ ‡å‡†é¡ºåº: book_id, chapter_id, page
        import re
        
        book_id = ''
        chapter_id = ''
        
        # æå–æ‰€æœ‰æ•°å­—åºåˆ—ï¼ˆæŒ‰ç…§åœ¨URLä¸­å‡ºç°çš„é¡ºåºï¼‰
        numbers = re.findall(r'\d+', chapter_url)
        
        if len(numbers) >= 2:
            # æ ‡å‡†æƒ…å†µ: è‡³å°‘æœ‰ä¸¤ä¸ªæ•°å­—ï¼Œç¬¬ä¸€ä¸ªæ˜¯book_idï¼Œç¬¬äºŒä¸ªæ˜¯chapter_id
            book_id = numbers[0]
            chapter_id = numbers[1]
        elif len(numbers) == 1:
            # åªæœ‰ä¸€ä¸ªæ•°å­—ï¼Œä½œä¸ºchapter_idï¼Œbook_idä½¿ç”¨self.book_id
            chapter_id = numbers[0]
            book_id = self.book_id or ''
        else:
            logger.warning(f"æ— æ³•ä»URLæå–ID: {chapter_url}")
            return None
        
        # æ„å»ºURL
        try:
            next_url = url_pattern.format(
                base_url=self.base_url,
                book_id=book_id,
                chapter_id=chapter_id,
                page=page
            )
            logger.debug(f"æ„å»ºç¿»é¡µURL: {next_url} (book_id={book_id}, chapter_id={chapter_id}, page={page})")
            return next_url
        except KeyError as e:
            logger.error(f"URLæ¨¡å¼å˜é‡é”™è¯¯: {e}, pattern: {url_pattern}")
            return None
    
    def _parse_chapters_from_page(self, html: str, chapter_list_config: Dict) -> List[Dict]:
        """ä»é¡µé¢è§£æç« èŠ‚åˆ—è¡¨"""
        chapters = []
        
        # éªŒè¯é…ç½®ç±»å‹
        if not isinstance(chapter_list_config, dict):
            raise TypeError(f"chapter_list_config åº”ä¸ºå­—å…¸ç±»å‹ï¼Œå®é™…ä¸º {type(chapter_list_config).__name__}")
        
        # è·å–ç« èŠ‚é¡¹é…ç½®
        items_config = chapter_list_config.get('items')
        title_config = chapter_list_config.get('title')
        url_config = chapter_list_config.get('url')
        
        # éªŒè¯å¿…éœ€å­—æ®µ
        if not items_config:
            raise ValueError("chapter_list_config ç¼ºå°‘ 'items' å­—æ®µ")
        if not title_config:
            raise ValueError("chapter_list_config ç¼ºå°‘ 'title' å­—æ®µ")
        if not url_config:
            raise ValueError("chapter_list_config ç¼ºå°‘ 'url' å­—æ®µ")
        
        # éªŒè¯å­—æ®µç±»å‹
        if not isinstance(items_config, dict):
            raise TypeError(f"items é…ç½®åº”ä¸ºå­—å…¸ç±»å‹ï¼Œå®é™…ä¸º {type(items_config).__name__}")
        if not isinstance(title_config, dict):
            raise TypeError(f"title é…ç½®åº”ä¸ºå­—å…¸ç±»å‹ï¼Œå®é™…ä¸º {type(title_config).__name__}")
        if not isinstance(url_config, dict):
            raise TypeError(f"url é…ç½®åº”ä¸ºå­—å…¸ç±»å‹ï¼Œå®é™…ä¸º {type(url_config).__name__}")
        
        # å…ˆè·å–æ‰€æœ‰ç« èŠ‚é¡¹
        root = Selector(text=html)
        items_xpath = items_config.get('expression', '')
        if not items_xpath:
            raise ValueError("items é…ç½®ç¼ºå°‘ 'expression' å­—æ®µ")
        
        chapter_items = root.xpath(items_xpath)
        
        for item in chapter_items:
            try:
                # è§£ææ ‡é¢˜
                title_expr = title_config.get('expression', '')
                if not title_expr:
                    continue
                title = item.xpath(title_expr).get()
                
                # è§£æURL
                url_expr = url_config.get('expression', '')
                if not url_expr:
                    continue
                url = item.xpath(url_expr).get()
                
                if title and url:
                    # åå¤„ç†
                    if title_config.get('process'):
                        title = self.parser.apply_post_process(title, title_config['process'])
                    
                    # æ„å»ºå®Œæ•´URL
                    chapter_url = urljoin(self.base_url, url)
                    
                    chapters.append({
                        'title': title,
                        'url': chapter_url,
                        'content': ''
                    })
            except Exception as e:
                logger.warning(f"âš ï¸  è§£æç« èŠ‚é¡¹å¤±è´¥: {e}")
                continue
        
        return chapters
    
    def download_chapter_content(self, chapter_url: str) -> str:
        """
        ä¸‹è½½ç« èŠ‚å†…å®¹ï¼ˆæ”¯æŒå¤šé¡µï¼‰
        :param chapter_url: ç« èŠ‚URL
        :return: å®Œæ•´å†…å®¹
        """
        all_content = []
        current_url = chapter_url
        page_num = 1
        
        parsers = self.config_manager.get_parsers()
        chapter_content_config = parsers.get('chapter_content', {})
        
        max_pages = chapter_content_config.get('max_pages', 50)
        content_config = chapter_content_config.get('content', {})
        next_page_config = chapter_content_config.get('next_page', {})
        clean_config = chapter_content_config.get('clean', [])
        
        while current_url and page_num <= max_pages:
            html = self.fetcher.get_page(current_url,
                                        max_retries=self.config_manager.get_max_retries())
            if not html:
                logger.warning(f"âš ï¸  ç¬¬{page_num}é¡µè·å–å¤±è´¥")
                break
            
            # è§£æå†…å®¹
            content = self.parser.parse_with_config(html, content_config)
            if content:
                if isinstance(content, list):
                    content = '\n'.join([str(c).strip() for c in content if str(c).strip()])
                all_content.append(content)
            
            # æ£€æŸ¥æ˜¯å¦æœ‰ä¸‹ä¸€é¡µ
            if next_page_config and next_page_config.get('enabled', False):
                # ä¼˜å…ˆä½¿ç”¨url_patternæ„å»ºURL
                if next_page_config.get('url_pattern'):
                    next_url = self._build_content_next_page_url(
                        chapter_url, page_num + 1, next_page_config
                    )
                else:
                    # ä½¿ç”¨XPathæå–é“¾æ¥
                    next_url = self.parser.parse_with_config(html, next_page_config)
                    if next_url:
                        next_url = urljoin(self.base_url, next_url)
                
                if next_url and next_url != current_url:
                    current_url = next_url
                    page_num += 1
                else:
                    break
            else:
                break
        
        # åˆå¹¶å†…å®¹
        final_content = '\n\n'.join(all_content) if all_content else ''
        
        # æ¸…ç†å†…å®¹
        if clean_config:
            for clean_rule in clean_config:
                final_content = self.parser.apply_post_process(final_content, [clean_rule])
        
        return final_content
    
    def download_and_save_chapter(self, index: int) -> bool:
        """ä¸‹è½½å¹¶ä¿å­˜å•ä¸ªç« èŠ‚"""
        # æ£€æŸ¥æ˜¯å¦éœ€è¦åœæ­¢
        if self._check_stop():
            self._log('WARNING', 'âš ï¸  æ”¶åˆ°åœæ­¢ä¿¡å·ï¼Œç»ˆæ­¢ä¸‹è½½')
            return False
        
        chapter = self.chapters[index]
        chapter_url = chapter['url']
        chapter_title = chapter['title']
        
        # æ£€æŸ¥æ˜¯å¦å·²ä¸‹è½½
        if self.is_chapter_downloaded(chapter_url):
            with self.progress_lock:
                self.skipped_count += 1
                self.completed_count += 1
                progress = (self.completed_count / len(self.chapters)) * 100
                msg = f"â­ï¸  [{self.completed_count}/{len(self.chapters)}] {chapter_title} (å·²ä¸‹è½½,è·³è¿‡) - è¿›åº¦: {progress:.1f}%"
                self._log('INFO', msg)
                # æ›´æ–°è¿›åº¦
                self._update_progress(
                    total=len(self.chapters),
                    completed=self.completed_count,
                    failed=len(self.redis_cli.smembers(self.redis_failed_key)) if self.redis_cli else 0,
                    current=chapter_title
                )
            return True
        
        # ä¸‹è½½å†…å®¹
        content = self.download_chapter_content(chapter_url)
        chapter['content'] = content
        
        # æ£€æŸ¥å†…å®¹æ˜¯å¦ä¸ºç©º
        if not content or len(content.strip()) == 0:
            self._log('ERROR', f"âŒ {chapter_title} å†…å®¹ä¸ºç©º")
            self.mark_chapter_failed(chapter_url)
            with self.progress_lock:
                self.completed_count += 1
                # æ›´æ–°è¿›åº¦
                self._update_progress(
                    total=len(self.chapters),
                    completed=self.completed_count,
                    failed=len(self.redis_cli.smembers(self.redis_failed_key)) if self.redis_cli else 0,
                    current=chapter_title
                )
            return False
        
        # ä¿å­˜åˆ°æ•°æ®åº“
        download_success = False
        db = NovelDatabase(**DB_CONFIG, silent=True)
        if db.connect():
            try:
                db.insert_chapter(
                    self.novel_id,
                    index + 1,
                    chapter_title,
                    content,
                    chapter_url
                )
                db.close()
                download_success = True
            except Exception as e:
                self._log('ERROR', f"âŒ {chapter_title} æ•°æ®åº“ä¿å­˜å¤±è´¥: {e}")
                db.close()
                download_success = False
        
        # æ›´æ–°Redisè®°å½•
        if download_success:
            self.mark_chapter_success(chapter_url)
            status_icon = "âœ…"
        else:
            self.mark_chapter_failed(chapter_url)
            status_icon = "âŒ"
        
        # æ›´æ–°è¿›åº¦
        with self.progress_lock:
            self.completed_count += 1
            progress = (self.completed_count / len(self.chapters)) * 100
            msg = f"{status_icon} [{self.completed_count}/{len(self.chapters)}] {chapter_title} ({len(content)} å­—) - è¿›åº¦: {progress:.1f}%"
            self._log('INFO' if download_success else 'ERROR', msg)
            
            # è°ƒç”¨è¿›åº¦å›è°ƒ
            self._update_progress(
                total=len(self.chapters),
                completed=self.completed_count,
                failed=len(self.redis_cli.smembers(self.redis_failed_key)) if self.redis_cli else 0,
                current=chapter_title
            )
        
        # å»¶è¿Ÿ
        delay = self.config_manager.get_delay()
        time.sleep(delay)
        
        return download_success
    
    def download_all_chapters(self, retry_failed: bool = False) -> bool:
        """
        å¤šçº¿ç¨‹å¹¶å‘ä¸‹è½½æ‰€æœ‰ç« èŠ‚
        :param retry_failed: æ˜¯å¦é‡è¯•å¤±è´¥çš„ç« èŠ‚
        :return: æ˜¯å¦æˆåŠŸ
        """
        if not self.parse_chapter_list():
            logger.error("âŒ è·å–ç« èŠ‚åˆ—è¡¨å¤±è´¥")
            return False
        
        # æ˜¾ç¤ºç»Ÿè®¡
        success_count, failed_count = self.get_download_stats()
        logger.info(f"ğŸ“Š Redisç»Ÿè®¡: å·²æˆåŠŸ {success_count} ç« ï¼Œå¤±è´¥ {failed_count} ç« ")
        
        if retry_failed and failed_count > 0:
            logger.info(f"ğŸ”„ å‡†å¤‡é‡è¯• {failed_count} ä¸ªå¤±è´¥çš„ç« èŠ‚")
            self.clear_failed_records()
        
        # è¿æ¥æ•°æ®åº“
        if not self.db.connect():
            logger.error("âŒ æ•°æ®åº“è¿æ¥å¤±è´¥")
            return False
        
        # æ£€æŸ¥å°è¯´æ˜¯å¦å·²å­˜åœ¨
        existing_novel = self.db.get_novel_by_url(self.start_url)
        if existing_novel:
            self.novel_id = existing_novel['id']
            logger.info(f"ğŸ“š å°è¯´å·²å­˜åœ¨ (ID: {self.novel_id})ï¼Œå°†æ›´æ–°ç« èŠ‚\n")
        else:
            # æ’å…¥å°è¯´ä¿¡æ¯
            self.novel_id = self.db.insert_novel(
                self.novel_info.get('title'),
                self.novel_info.get('author', 'æœªçŸ¥'),
                self.start_url,
                cover_url=self.novel_info.get('cover_url', '')
            )
            if not self.novel_id:
                logger.error("âŒ ä¿å­˜å°è¯´ä¿¡æ¯å¤±è´¥")
                return False
            logger.info(f"âœ… å°è¯´ä¿¡æ¯å·²ä¿å­˜ (ID: {self.novel_id})\n")
        
        self.db.close()
        
        # å¤šçº¿ç¨‹ä¸‹è½½
        logger.info("=" * 60)
        logger.info(f"ğŸš€ å¼€å§‹å¹¶å‘ä¸‹è½½ç« èŠ‚å†…å®¹ (çº¿ç¨‹æ•°: {self.max_workers})")
        logger.info("=" * 60)
        
        self.completed_count = 0
        self.skipped_count = 0
        start_time = time.time()
        
        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            futures = {executor.submit(self.download_and_save_chapter, i): i
                      for i in range(len(self.chapters))}
            
            for future in as_completed(futures):
                index = futures[future]
                try:
                    future.result()
                except Exception as e:
                    logger.error(f"âŒ ç« èŠ‚ {index + 1} ä¸‹è½½å¤±è´¥: {e}")
        
        elapsed_time = time.time() - start_time
        
        # æ›´æ–°ç»Ÿè®¡
        if self.db.connect():
            self.db.update_novel_stats(self.novel_id)
            self.db.close()
        
        final_success, final_failed = self.get_download_stats()
        new_downloads = self.completed_count - self.skipped_count
        
        logger.info("\n" + "=" * 60)
        logger.info(f"âœ… æ‰€æœ‰ç« èŠ‚å¤„ç†å®Œæˆï¼")
        logger.info(f"   æ€»è€—æ—¶: {elapsed_time:.2f} ç§’")
        logger.info(f"   æ€»ç« èŠ‚: {len(self.chapters)}")
        logger.info(f"   æ–°ä¸‹è½½: {new_downloads} ç« ")
        logger.info(f"   è·³è¿‡(å·²ä¸‹è½½): {self.skipped_count} ç« ")
        logger.info(f"   æˆåŠŸ: {final_success} ç« ")
        logger.info(f"   å¤±è´¥: {final_failed} ç« ")
        logger.info("=" * 60)
        
        return True
    
    def retry_failed_chapters(self) -> bool:
        """åªé‡è¯•å¤±è´¥çš„ç« èŠ‚"""
        logger.info("=" * 60)
        logger.info("ğŸ”„ å¼€å§‹é‡è¯•å¤±è´¥çš„ç« èŠ‚")
        logger.info("=" * 60)
        
        try:
            # è·å–å¤±è´¥ç« èŠ‚URL
            failed_urls = self.redis_cli.smembers(self.redis_failed_key)
            if not failed_urls:
                logger.info("âœ… æ²¡æœ‰å¤±è´¥çš„ç« èŠ‚éœ€è¦é‡è¯•")
                return True
            
            failed_urls = [url.decode('utf-8') if isinstance(url, bytes) else url for url in failed_urls]
            logger.info(f"ğŸ“‹ å…±æœ‰ {len(failed_urls)} ä¸ªå¤±è´¥ç« èŠ‚éœ€è¦é‡è¯•")
            
            # è§£æç« èŠ‚åˆ—è¡¨
            if not self.parse_chapter_list():
                logger.error("âŒ è·å–ç« èŠ‚åˆ—è¡¨å¤±è´¥")
                return False
            
            # è·å–å°è¯´ID
            if not self.db.connect():
                logger.error("âŒ æ•°æ®åº“è¿æ¥å¤±è´¥")
                return False
            
            existing_novel = self.db.get_novel_by_url(self.start_url)
            if existing_novel:
                self.novel_id = existing_novel['id']
            else:
                logger.error("âŒ å°è¯´ä¸å­˜åœ¨")
                self.db.close()
                return False
            
            self.db.close()
            
            # ç­›é€‰éœ€è¦é‡è¯•çš„ç« èŠ‚
            retry_chapters = []
            for idx, chapter in enumerate(self.chapters):
                if chapter['url'] in failed_urls:
                    retry_chapters.append((idx, chapter))
            
            logger.info(f"ğŸ¯ åŒ¹é…åˆ° {len(retry_chapters)} ä¸ªç« èŠ‚éœ€è¦é‡è¯•")
            
            if not retry_chapters:
                logger.info("âœ… æ²¡æœ‰åŒ¹é…çš„ç« èŠ‚éœ€è¦é‡è¯•")
                return True
            
            # æ¸…é™¤å¤±è´¥è®°å½•
            self.clear_failed_records()
            
            # å¤šçº¿ç¨‹é‡è¯•
            self.completed_count = 0
            self.skipped_count = 0
            start_time = time.time()
            
            with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
                futures = {executor.submit(self.download_and_save_chapter, idx): idx
                          for idx, chapter in retry_chapters}
                
                for future in as_completed(futures):
                    index = futures[future]
                    try:
                        future.result()
                    except Exception as e:
                        logger.error(f"âŒ ç« èŠ‚ {index + 1} é‡è¯•å¤±è´¥: {e}")
            
            elapsed_time = time.time() - start_time
            final_success, final_failed = self.get_download_stats()
            
            logger.info("\n" + "=" * 60)
            logger.info(f"âœ… é‡è¯•å®Œæˆï¼")
            logger.info(f"   è€—æ—¶: {elapsed_time:.2f} ç§’")
            logger.info(f"   é‡è¯•ç« èŠ‚: {len(retry_chapters)}")
            logger.info(f"   å½“å‰æˆåŠŸ: {final_success} ç« ")
            logger.info(f"   å½“å‰å¤±è´¥: {final_failed} ç« ")
            logger.info("=" * 60)
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ é‡è¯•å¤±è´¥ç« èŠ‚æ—¶å‡ºé”™: {e}")
            return False
    
    def print_summary(self):
        """æ‰“å°ä¸‹è½½æ‘˜è¦"""
        success_count, failed_count = self.get_download_stats()
        
        logger.info(f"\n{'=' * 60}")
        logger.info(f"âœ… ä¸‹è½½å®Œæˆï¼")
        logger.info(f"{'=' * 60}")
        logger.info(f"å°è¯´ID: {self.novel_id}")
        logger.info(f"å°è¯´åç§°: {self.novel_info.get('title')}")
        logger.info(f"ä½œè€…: {self.novel_info.get('author', 'æœªçŸ¥')}")
        logger.info(f"ç« èŠ‚æ€»æ•°: {len(self.chapters)}")
        logger.info(f"æˆåŠŸç« èŠ‚: {success_count}")
        logger.info(f"å¤±è´¥ç« èŠ‚: {failed_count}")
        
        total_words = sum(len(ch['content']) for ch in self.chapters)
        logger.info(f"æ€»å­—æ•°: {total_words:,} å­—")
        logger.info(f"{'=' * 60}")
    
    def run(self):
        """
        è¿è¡Œçˆ¬è™«ï¼ˆå®Œæ•´æµç¨‹ï¼‰
        1. è§£æç« èŠ‚åˆ—è¡¨
        2. ä¸‹è½½æ‰€æœ‰ç« èŠ‚
        3. æ‰“å°æ‘˜è¦
        """
        try:
            self._log('INFO', "=" * 60)
            self._log('INFO', f"ğŸš€ å¼€å§‹è¿è¡Œçˆ¬è™«: {self.site_name}")
            self._log('INFO', f"ğŸ“– ä¹¦ç±ID: {self.book_id}")
            self._log('INFO', "=" * 60)
            
            # 1. è§£æç« èŠ‚åˆ—è¡¨
            if not self.parse_chapter_list():
                self._log('ERROR', "âŒ è§£æç« èŠ‚åˆ—è¡¨å¤±è´¥")
                return False
            
            # æ£€æŸ¥åœæ­¢æ ‡å¿—
            if self._check_stop():
                self._log('WARNING', 'âš ï¸  ä»»åŠ¡è¢«åœæ­¢')
                return False
            
            # 2. ä¸‹è½½æ‰€æœ‰ç« èŠ‚
            if not self.download_all_chapters():
                self._log('ERROR', "âŒ ä¸‹è½½ç« èŠ‚å¤±è´¥")
                return False
            
            # 3. æ‰“å°æ‘˜è¦
            self.print_summary()
            
            self._log('INFO', "=" * 60)
            self._log('SUCCESS', "âœ… çˆ¬è™«è¿è¡Œå®Œæˆï¼")
            self._log('INFO', "=" * 60)
            
            return True
            
        except Exception as e:
            self._log('ERROR', f"âŒ çˆ¬è™«è¿è¡Œå¤±è´¥: {e}")
            raise
