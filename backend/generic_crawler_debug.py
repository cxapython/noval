#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é€šç”¨çˆ¬è™«è°ƒè¯•ç±» - ç”¨äºé…ç½®æµ‹è¯•å’Œè°ƒè¯•
ç»§æ‰¿è‡ª GenericNovelCrawlerï¼Œæ·»åŠ è¯¦ç»†çš„è°ƒè¯•ä¿¡æ¯
"""
import sys
from pathlib import Path
from typing import Dict, List, Any, Tuple
from urllib.parse import urljoin
import re

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„ï¼ˆæ”¯æŒç›´æ¥è¿è¡Œï¼‰
if __name__ == "__main__":
    project_root = Path(__file__).parent.parent
    sys.path.insert(0, str(project_root))

# å¯¼å…¥æ¨¡å—ï¼ˆå…¼å®¹ç›¸å¯¹å¯¼å…¥å’Œç›´æ¥è¿è¡Œï¼‰
try:
    from .generic_crawler import GenericNovelCrawler
except ImportError:
    from backend.generic_crawler import GenericNovelCrawler

from loguru import logger

# è¾…åŠ©å‡½æ•°
def safe_int(value, default=0):
    """å®‰å…¨åœ°å°†å€¼è½¬æ¢ä¸ºæ•´æ•°"""
    if isinstance(value, int):
        return value
    if isinstance(value, str):
        try:
            return int(value)
        except (ValueError, TypeError):
            return default
    if isinstance(value, float):
        return int(value)
    return default

def safe_bool(value, default=False):
    """å®‰å…¨åœ°å°†å€¼è½¬æ¢ä¸ºå¸ƒå°”å€¼"""
    if isinstance(value, bool):
        return value
    if isinstance(value, str):
        return value.lower() in ('true', '1', 'yes', 'on')
    if isinstance(value, (int, float)):
        return bool(value)
    return default


class GenericNovelCrawlerDebug(GenericNovelCrawler):
    """
    é€šç”¨çˆ¬è™«è°ƒè¯•ç‰ˆæœ¬
    ç»§æ‰¿è‡ª GenericNovelCrawlerï¼Œé‡å†™éƒ¨åˆ†æ–¹æ³•ä»¥æ”¯æŒè°ƒè¯•ä¿¡æ¯è¾“å‡º
    """
    
    def _apply_post_process_debug(self, data: Any, processes: List[Dict]) -> Tuple[Any, List[Dict]]:
        """
        åº”ç”¨åå¤„ç†ï¼ˆè°ƒè¯•ç‰ˆæœ¬ï¼‰
        :param data: åŸå§‹æ•°æ®
        :param processes: å¤„ç†æ­¥éª¤åˆ—è¡¨
        :return: (å¤„ç†åçš„æ•°æ®, è°ƒè¯•ä¿¡æ¯åˆ—è¡¨)
        """
        result = data
        debug_info = []
        
        for i, process in enumerate(processes):
            method = process.get('method', '')
            params = process.get('params', {})
            before_value = result
            matched = False
            match_type = None
            
            try:
                if method == 'strip':
                    if isinstance(result, str):
                        result = result.strip(params.get('chars', None))
                        matched = before_value != result
                    elif isinstance(result, list):
                        result = [item.strip(params.get('chars', None)) if isinstance(item, str) else item for item in result]
                        matched = before_value != result
                
                elif method == 'replace':
                    old = params.get('old', '')
                    new = params.get('new', '')
                    # æ™ºèƒ½å¤„ç†ï¼šè‡ªåŠ¨å¤„ç†æ™®é€šç©ºæ ¼å’Œ\xa0ï¼ˆä¸é—´æ–­ç©ºæ ¼ï¼‰çš„å…¼å®¹æ€§
                    if isinstance(result, str):
                        # è®°å½•åŒ¹é…ä½ç½®çš„ä¸Šä¸‹æ–‡ï¼ˆç”¨äºè°ƒè¯•æ˜¾ç¤ºï¼‰
                        match_context_before = None
                        match_context_after = None
                        context_length = 80  # å‰åå„80å­—çš„ä¸Šä¸‹æ–‡
                        
                        # å…ˆå°è¯•ç›´æ¥æ›¿æ¢
                        if old in result:
                            # æ‰¾åˆ°ç¬¬ä¸€ä¸ªåŒ¹é…ä½ç½®
                            match_pos = result.find(old)
                            # æå–ä¸Šä¸‹æ–‡
                            start = max(0, match_pos - context_length)
                            end = min(len(result), match_pos + len(old) + context_length)
                            match_context_before = result[start:end]
                            
                            # æ‰§è¡Œæ›¿æ¢
                            result = result.replace(old, new)
                            matched = True
                            match_type = 'ç²¾ç¡®åŒ¹é…'
                            
                            # è®¡ç®—æ›¿æ¢åçš„ä¸Šä¸‹æ–‡
                            after_match_pos = match_pos
                            after_end = min(len(result), after_match_pos + len(new) + context_length)
                            match_context_after = result[start:after_end]
                        else:
                            # å°è¯•å°†resultå’Œoldéƒ½æ ‡å‡†åŒ–ä¸ºæ™®é€šç©ºæ ¼ååŒ¹é…
                            normalized_result = result.replace('\xa0', ' ')
                            normalized_old = old.replace('\xa0', ' ')
                            if normalized_old in normalized_result:
                                # æ‰¾åˆ°åŒ¹é…ä½ç½®
                                match_pos = normalized_result.find(normalized_old)
                                start = max(0, match_pos - context_length)
                                end = min(len(normalized_result), match_pos + len(normalized_old) + context_length)
                                match_context_before = normalized_result[start:end]
                                
                                # æ‰§è¡Œæ›¿æ¢
                                result = normalized_result.replace(normalized_old, new)
                                matched = True
                                match_type = 'æ™ºèƒ½åŒ¹é…ï¼ˆç©ºæ ¼æ ‡å‡†åŒ–ï¼‰'
                                
                                # æ›¿æ¢åçš„ä¸Šä¸‹æ–‡
                                after_match_pos = match_pos
                                after_end = min(len(result), after_match_pos + len(new) + context_length)
                                match_context_after = result[start:after_end]
                            else:
                                matched = False
                                match_type = 'æœªåŒ¹é…'
                    elif isinstance(result, list):
                        old_result = result
                        result = [item.replace(old, new) if isinstance(item, str) else item for item in result]
                        matched = old_result != result
                
                elif method == 'regex_replace':
                    pattern = params.get('pattern', '')
                    repl = params.get('repl', '')
                    if isinstance(result, str):
                        new_result = re.sub(pattern, repl, result)
                        matched = new_result != result
                        result = new_result
                    elif isinstance(result, list):
                        old_result = result
                        result = [re.sub(pattern, repl, item) if isinstance(item, str) else item for item in result]
                        matched = old_result != result
                
                elif method == 'join':
                    if isinstance(result, list):
                        separator = params.get('separator', '')
                        result = separator.join([str(item) for item in result])
                        matched = True
                
                elif method == 'split':
                    if isinstance(result, str):
                        separator = params.get('separator', ' ')
                        result = result.split(separator)
                        matched = True
                
                elif method == 'extract_first':
                    if isinstance(result, list) and len(result) > 0:
                        result = result[0]
                        matched = True
                
                elif method == 'extract_index':
                    if isinstance(result, list):
                        idx = params.get('index', 0)
                        if len(result) > idx:
                            result = result[idx]
                            matched = True
                
                # è®°å½•è°ƒè¯•ä¿¡æ¯
                debug_entry = {
                    'step': i + 1,
                    'method': method,
                    'params': params,
                    'before': str(before_value)[:100] if isinstance(before_value, str) else str(before_value),
                    'after': str(result)[:100] if isinstance(result, str) else str(result),
                    'matched': matched,
                    'match_type': match_type,
                    'changed': before_value != result
                }
                
                # å¦‚æœæ˜¯ replace æ–¹æ³•ä¸”æœ‰åŒ¹é…ä¸Šä¸‹æ–‡ï¼Œä½¿ç”¨ä¸Šä¸‹æ–‡æ›¿ä»£ç®€å•æˆªå–
                if method == 'replace' and 'match_context_before' in locals() and match_context_before:
                    debug_entry['before'] = match_context_before
                    debug_entry['after'] = match_context_after if match_context_after else str(result)[:100]
                    debug_entry['match_position'] = 'context'
                
                debug_info.append(debug_entry)
            
            except Exception as e:
                logger.warning(f"âš ï¸  åå¤„ç†å¤±è´¥ ({method}): {e}")
                debug_info.append({
                    'step': i + 1,
                    'method': method,
                    'params': params,
                    'error': str(e),
                    'matched': False
                })
        
        return result, debug_info
    
    def parse_novel_info_debug(self, html: str) -> Dict:
        """è§£æå°è¯´ä¿¡æ¯ï¼ˆè°ƒè¯•æ¨¡å¼ï¼Œè¿”å›è¯¦ç»†çš„å¤„ç†æ­¥éª¤ï¼‰"""
        novel_info = {}
        debug_details = {}
        
        parsers = self.config_manager.get_parsers().get('novel_info', {})
        
        # éªŒè¯é…ç½®ç±»å‹
        if not isinstance(parsers, dict):
            logger.error(f"âŒ novel_info é…ç½®åº”ä¸ºå­—å…¸ç±»å‹ï¼Œå®é™…ä¸º {type(parsers).__name__}")
            return {'data': novel_info, 'debug': {}}
        
        for field, parser_config in parsers.items():
            # è·³è¿‡æ³¨é‡Šå­—æ®µ
            if field.startswith('_'):
                continue
            
            try:
                # é¦–å…ˆè§£æåŸå§‹å€¼
                parse_type = parser_config.get('type', 'xpath')
                expression = parser_config.get('expression', '')
                index = parser_config.get('index', -1)
                post_process = parser_config.get('process', [])
                
                raw_value = None
                if parse_type == 'xpath':
                    from parsel import Selector
                    root = Selector(text=html)
                    all_results = root.xpath(expression).getall()
                    if index is None or (isinstance(index, int) and index == 999):
                        raw_value = all_results
                    elif all_results:
                        try:
                            raw_value = all_results[index]
                        except IndexError:
                            raw_value = None
                
                # åº”ç”¨åå¤„ç†å¹¶è·å–è°ƒè¯•ä¿¡æ¯
                if raw_value is not None and post_process:
                    value, process_debug = self._apply_post_process_debug(raw_value, post_process)
                else:
                    value = raw_value
                    process_debug = []
                
                novel_info[field] = value
                debug_details[field] = {
                    'raw_value': str(raw_value)[:200] if raw_value else None,
                    'final_value': str(value)[:200] if value else None,
                    'post_process_steps': process_debug
                }
                
            except Exception as e:
                logger.warning(f"âš ï¸  è§£æå­—æ®µ {field} å¤±è´¥: {e}")
                novel_info[field] = None
                debug_details[field] = {'error': str(e)}
        
        return {'data': novel_info, 'debug': debug_details}
    
    def download_chapter_content_debug(self, chapter_url: str) -> Dict:
        """
        ä¸‹è½½ç« èŠ‚å†…å®¹ï¼ˆè°ƒè¯•æ¨¡å¼ï¼Œè¿”å›è¯¦ç»†çš„å¤„ç†æ­¥éª¤ï¼‰
        :param chapter_url: ç« èŠ‚URL
        :return: {'content': å†…å®¹, 'debug': è°ƒè¯•ä¿¡æ¯}
        """
        all_content = []
        current_url = chapter_url
        page_num = 1
        
        parsers = self.config_manager.get_parsers()
        chapter_content_config = parsers.get('chapter_content', {})
        
        content_config = chapter_content_config.get('content', {})
        next_page_config = chapter_content_config.get('next_page', {})
        clean_config = chapter_content_config.get('clean', [])
        
        # è·å–æœ€å¤§é¡µæ•°ï¼šä¼˜å…ˆä»next_pageé…ç½®è¯»å–ï¼Œå…¼å®¹æ—§é…ç½®
        max_pages_manual = safe_int(next_page_config.get('max_pages_manual') or chapter_content_config.get('max_pages', 50), 50)
        max_page_xpath_config = next_page_config.get('max_page_xpath')
        
        # åˆå§‹åŒ–æœ€å¤§é¡µæ•°ï¼ˆé»˜è®¤ä½¿ç”¨æ‰‹åŠ¨é…ç½®çš„å€¼ï¼‰
        max_pages = max_pages_manual
        
        debug_info = {
            'pages_processed': 0,
            'raw_content_length': 0,
            'final_content_length': 0,
            'clean_steps': [],
            'max_pages_config': {
                'manual': max_pages_manual,
                'extracted': None,
                'final': max_pages
            }
        }
        
        # è·å–å†…å®¹
        while current_url and page_num <= max_pages:
            html = self.fetcher.get_page(current_url, max_retries=self.config_manager.get_max_retries())
            if not html:
                logger.warning(f"âš ï¸  ç¬¬{page_num}é¡µè·å–å¤±è´¥")
                break
            
            # ç¬¬ä¸€é¡µæ—¶å°è¯•ä»é¡µé¢æå–æœ€å¤§é¡µæ•°ï¼ˆè°ƒç”¨çˆ¶ç±»æ–¹æ³•ï¼‰
            if page_num == 1:
                max_pages = self._extract_max_pages_from_html(html, max_page_xpath_config, max_pages_manual)
                # è®°å½•è°ƒè¯•ä¿¡æ¯
                if max_pages != max_pages_manual:
                    debug_info['max_pages_config']['extracted'] = max_pages
                debug_info['max_pages_config']['final'] = max_pages
            
            debug_info['pages_processed'] = page_num
            
            # è§£æå†…å®¹
            content = self.parser.parse_with_config(html, content_config)
            if content:
                if isinstance(content, list):
                    content = '\n'.join([str(c).strip() for c in content if str(c).strip()])
                all_content.append(content)
            
            # æ£€æŸ¥æ˜¯å¦æœ‰ä¸‹ä¸€é¡µ
            if next_page_config and safe_bool(next_page_config.get('enabled', False), False):
                # ä¼˜å…ˆä½¿ç”¨url_patternæ„å»ºURL
                if next_page_config.get('url_pattern', '').strip():
                    next_url = self._build_content_next_page_url(
                        chapter_url, page_num + 1, next_page_config
                    )
                else:
                    # ä½¿ç”¨XPathæå–é“¾æ¥
                    next_url = self.parser.parse_with_config(html, next_page_config)
                    if next_url:
                        next_url = urljoin(self.base_url, next_url)
                
                if next_url and next_url != current_url:
                    current_url = next_url
                    page_num += 1
                else:
                    break
            else:
                break
        
        # åˆå¹¶å†…å®¹
        final_content = '\n\n'.join(all_content) if all_content else ''
        debug_info['raw_content_length'] = len(final_content)
        
        # æ¸…ç†å†…å®¹ï¼ˆå¸¦è°ƒè¯•ä¿¡æ¯ï¼‰
        if clean_config:
            for i, clean_rule in enumerate(clean_config):
                before_content = final_content
                if isinstance(clean_rule, dict):
                    final_content, step_debug = self._apply_post_process_debug(final_content, [clean_rule])
                    if step_debug and len(step_debug) > 0:
                        debug_info['clean_steps'].append({
                            'rule_index': i + 1,
                            'method': clean_rule.get('method', 'unknown'),
                            'params': clean_rule.get('params', {}),
                            'before_length': len(before_content),
                            'after_length': len(final_content),
                            'changed': before_content != final_content,
                            'step_details': step_debug[0] if step_debug else {}
                        })
        
        debug_info['final_content_length'] = len(final_content)
        
        return {
            'content': final_content,
            'debug': debug_info
        }


# ============================================================================
# PyCharm è°ƒè¯•å…¥å£ - ç›´æ¥ä¿®æ”¹ä¸‹é¢çš„é…ç½®è¿›è¡Œè°ƒè¯•
# ============================================================================
if __name__ == "__main__":
    # ========== é…ç½®åŒºåŸŸ - åœ¨è¿™é‡Œä¿®æ”¹ä½ è¦æµ‹è¯•çš„é…ç½® ==========
    CONFIG_FILE = project_root / "configs" / "config_ikbook8.json"  # ä¿®æ”¹ä¸ºä½ çš„é…ç½®æ–‡ä»¶
    BOOK_ID = "10683"  # ä¿®æ”¹ä¸ºä½ è¦æµ‹è¯•çš„ä¹¦ç±ID
    MAX_WORKERS = 1  # è°ƒè¯•æ—¶å»ºè®®è®¾ä¸º1
    USE_PROXY = False  # æ˜¯å¦ä½¿ç”¨ä»£ç†
    
    # æµ‹è¯•é€‰é¡¹
    TEST_NOVEL_INFO = True  # æµ‹è¯•å°è¯´ä¿¡æ¯è§£æ
    TEST_CHAPTER_LIST = True  # æµ‹è¯•ç« èŠ‚åˆ—è¡¨è§£æ
    TEST_CHAPTER_CONTENT = True  # æµ‹è¯•ç« èŠ‚å†…å®¹è§£æï¼ˆä¼šæµ‹è¯•ç¬¬ä¸€ç« ï¼‰
    TEST_CHAPTER_INDEX = 0  # è¦æµ‹è¯•çš„ç« èŠ‚ç´¢å¼•
    # ======================================================
    
    logger.info("=" * 80)
    logger.info("ğŸ” PyCharm é…ç½®è°ƒè¯•å·¥å…·")
    logger.info("=" * 80)
    logger.info(f"é…ç½®æ–‡ä»¶: {CONFIG_FILE}")
    logger.info(f"ä¹¦ç±ID: {BOOK_ID}")
    logger.info("=" * 80)
    
    try:
        # åˆ›å»ºè°ƒè¯•çˆ¬è™«å®ä¾‹
        crawler = GenericNovelCrawlerDebug(
            config_file=str(CONFIG_FILE),
            book_id=BOOK_ID,
            max_workers=MAX_WORKERS,
            use_proxy=USE_PROXY
        )
        
        logger.success("âœ… çˆ¬è™«å®ä¾‹åˆ›å»ºæˆåŠŸ\n")
        
        # æµ‹è¯•1: å°è¯´ä¿¡æ¯è§£æ
        if TEST_NOVEL_INFO:
            logger.info("=" * 80)
            logger.info("ğŸ“ æµ‹è¯•1: å°è¯´ä¿¡æ¯è§£æ")
            logger.info("=" * 80)
            
            html = crawler.get_page(crawler.start_url)
            if html:
                result = crawler.parse_novel_info_debug(html)
                
                logger.info("\nğŸ“Š è§£æç»“æœ:")
                for field, value in result['data'].items():
                    logger.info(f"  {field}: {value}")
                
                logger.info("\nğŸ” è°ƒè¯•è¯¦æƒ…:")
                for field, debug in result['debug'].items():
                    logger.info(f"\n  å­—æ®µ: {field}")
                    logger.info(f"    åŸå§‹å€¼: {debug.get('raw_value', 'N/A')}")
                    logger.info(f"    æœ€ç»ˆå€¼: {debug.get('final_value', 'N/A')}")
                    
                    if 'post_process_steps' in debug and debug['post_process_steps']:
                        logger.info(f"    åå¤„ç†æ­¥éª¤:")
                        for step in debug['post_process_steps']:
                            logger.info(f"      æ­¥éª¤{step['step']}: {step['method']}")
                            logger.info(f"        å‚æ•°: {step['params']}")
                            logger.info(f"        åŒ¹é…: {'âœ…' if step.get('matched') else 'âŒ'}")
                            logger.info(f"        å˜åŒ–: {'æ˜¯' if step.get('changed') else 'å¦'}")
            else:
                logger.error("âŒ è·å–é¡µé¢å¤±è´¥")
        
        # æµ‹è¯•2: ç« èŠ‚åˆ—è¡¨è§£æ
        if TEST_CHAPTER_LIST:
            logger.info("\n" + "=" * 80)
            logger.info("ğŸ“ æµ‹è¯•2: ç« èŠ‚åˆ—è¡¨è§£æ")
            logger.info("=" * 80)
            
            if crawler.parse_chapter_list():
                logger.success(f"\nâœ… è§£ææˆåŠŸï¼Œå…± {len(crawler.chapters)} ç« ")
                
                logger.info("\nå‰5ç« é¢„è§ˆ:")
                for i, chapter in enumerate(crawler.chapters[:5]):
                    logger.info(f"  {i+1}. {chapter['title']}")
                    logger.info(f"     URL: {chapter['url']}")
            else:
                logger.error("âŒ è§£æç« èŠ‚åˆ—è¡¨å¤±è´¥")
        
        # æµ‹è¯•3: ç« èŠ‚å†…å®¹è§£æ
        if TEST_CHAPTER_CONTENT and len(crawler.chapters) > TEST_CHAPTER_INDEX:
            logger.info("\n" + "=" * 80)
            logger.info(f"ğŸ“ æµ‹è¯•3: ç« èŠ‚å†…å®¹è§£æï¼ˆç¬¬{TEST_CHAPTER_INDEX + 1}ç« ï¼‰")
            logger.info("=" * 80)
            
            test_chapter = crawler.chapters[TEST_CHAPTER_INDEX]
            logger.info(f"\næµ‹è¯•ç« èŠ‚: {test_chapter['title']}")
            logger.info(f"URL: {test_chapter['url']}")
            
            result = crawler.download_chapter_content_debug(test_chapter['url'])
            
            logger.info("\nğŸ“Š å†…å®¹ç»Ÿè®¡:")
            logger.info(f"  å¤„ç†é¡µæ•°: {result['debug']['pages_processed']}")
            logger.info(f"  åŸå§‹é•¿åº¦: {result['debug']['raw_content_length']} å­—")
            logger.info(f"  æœ€ç»ˆé•¿åº¦: {result['debug']['final_content_length']} å­—")
            
            if result['debug']['clean_steps']:
                logger.info("\nğŸ§¹ æ¸…ç†æ­¥éª¤:")
                for step in result['debug']['clean_steps']:
                    logger.info(f"\n  è§„åˆ™{step['rule_index']}: {step['method']}")
                    logger.info(f"    å‚æ•°: {step['params']}")
                    logger.info(f"    å‰: {step['before_length']} å­—")
                    logger.info(f"    å: {step['after_length']} å­—")
                    logger.info(f"    å˜åŒ–: {'âœ…' if step['changed'] else 'âŒ'}")
                    
                    # æ˜¾ç¤ºåŒ¹é…è¯¦æƒ…
                    if 'step_details' in step and step['step_details']:
                        details = step['step_details']
                        if details.get('matched'):
                            logger.info(f"    åŒ¹é…: âœ… ({details.get('match_type', 'æœªçŸ¥')})")
                            if details.get('before'):
                                logger.info(f"    åŒ¹é…ä¸Šä¸‹æ–‡:")
                                logger.info(f"      æ›¿æ¢å‰: {details['before'][:150]}")
                                logger.info(f"      æ›¿æ¢å: {details['after'][:150]}")
                        else:
                            logger.info(f"    åŒ¹é…: âŒ æœªæ‰¾åˆ°åŒ¹é…å†…å®¹")
            
            if result['content']:
                logger.info("\nğŸ“„ å†…å®¹é¢„è§ˆ:")
                logger.info(result['content'][:300] + "...")
                
                # ä¿å­˜åˆ°æ–‡ä»¶
                debug_file = project_root / "logs" / f"debug_chapter_{TEST_CHAPTER_INDEX}_content.txt"
                debug_file.parent.mkdir(parents=True, exist_ok=True)
                with open(debug_file, 'w', encoding='utf-8') as f:
                    f.write(result['content'])
                logger.info(f"\nğŸ’¾ å®Œæ•´å†…å®¹å·²ä¿å­˜åˆ°: {debug_file}")
            else:
                logger.error("âŒ å†…å®¹ä¸ºç©ºï¼")
        
        logger.info("\n" + "=" * 80)
        logger.success("âœ… è°ƒè¯•å®Œæˆï¼")
        logger.info("=" * 80)
        
    except Exception as e:
        logger.exception(f"âŒ è°ƒè¯•å¤±è´¥: {e}")
        raise

